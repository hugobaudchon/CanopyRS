from pathlib import Path

import geopandas as gpd

from geodataset.aggregator import Aggregator
from geodataset.utils import GeoPackageNameConvention, TileNameConvention

from engine.components.base import BaseComponent
from engine.config_parsers import AggregatorConfig
from engine.data_state import DataState
from engine.utils import infer_aoi_name, generate_future_coco, object_id_column_name


class AggregatorComponent(BaseComponent):
    name = 'aggregator'

    def __init__(self, config: AggregatorConfig, parent_output_path: str, component_id: int):
        super().__init__(config, parent_output_path, component_id)

    def __call__(self, data_state: DataState) -> DataState:
        # Determine which score columns are available and their corresponding weights.
        available_scores = []
        scores_weights = []
        if 'detector_score' in data_state.infer_gdf.columns:
            available_scores.append('detector_score')
            scores_weights.append(self.config.detector_score_weight)
        if 'segmenter_score' in data_state.infer_gdf.columns:
            available_scores.append('segmenter_score')
            scores_weights.append(self.config.segmenter_score_weight)

        # Determine naming for the aggregated output (using the first tileâ€™s name).
        tiles_path = data_state.infer_gdf['tile_path'].unique().tolist()
        product_name, scale_factor, ground_resolution, _, _, _ = TileNameConvention().parse_name(
            Path(tiles_path[0]).name
        )
        gpkg_name = GeoPackageNameConvention.create_name(
            product_name=product_name,
            fold=infer_aoi_name,
            scale_factor=scale_factor,
            ground_resolution=ground_resolution
        )
        pre_aggregated_gpkg_name = GeoPackageNameConvention.create_name(
            product_name=product_name,
            fold=f'{infer_aoi_name}notaggregated',
            scale_factor=scale_factor,
            ground_resolution=ground_resolution
        )

        # Run the aggregator
        aggregator = Aggregator.from_gdf(
            output_path=self.output_path / gpkg_name,
            gdf=data_state.infer_gdf,
            tiles_paths_column='tile_path',
            polygons_column='geometry',
            scores_column=available_scores if available_scores else None,
            other_attributes_columns=list(data_state.infer_gdf_columns_to_pass),
            scores_weights=scores_weights if scores_weights else None,
            scores_weighting_method=self.config.scores_weighting_method,
            min_centroid_distance_weight=self.config.min_centroid_distance_weight,
            score_threshold=self.config.score_threshold,
            nms_threshold=self.config.nms_threshold,
            nms_algorithm=self.config.nms_algorithm,
            best_geom_keep_area_ratio=0.5,
            edge_band_buffer_percentage=self.config.edge_band_buffer_percentage,
            pre_aggregated_output_path=self.output_path / pre_aggregated_gpkg_name,
        )
        results_gdf = aggregator.polygons_gdf

        # Generate COCO output asynchronously and update the data state
        columns_to_pass = data_state.infer_gdf_columns_to_pass.union({'aggregator_score'})

        future_coco = generate_future_coco(
            future_key='infer_coco_path',
            component_name=self.name,
            component_id=self.component_id,
            description="Aggregator inference",
            gdf=results_gdf,
            tiles_paths_column='tile_path',
            polygons_column='geometry',
            scores_column='aggregator_score',
            categories_column='segmenter_class' if 'segmenter_class' in results_gdf.columns
                              else 'detector_class' if 'detector_class' in results_gdf.columns
                              else None,
            other_attributes_columns=columns_to_pass,
            output_path=self.output_path,
            use_rle_for_labels=False,
            n_workers=4,
            coco_categories_list=None
        )

        return self.update_data_state(data_state, results_gdf, columns_to_pass, future_coco)

    def update_data_state(self,
                         data_state: DataState,
                         results_gdf: gpd.GeoDataFrame,
                         columns_to_pass: set,
                         future_coco: tuple) -> DataState:
        # Register the component folder
        data_state = self.register_outputs_base(data_state)

        # Register the GeoPackage files by finding them in the output directory
        # This approach avoids needing access to gpkg_name variables
        for file_path in self.output_path.glob("*.gpkg"):
            if "notaggregated" in file_path.name:
                data_state.register_output_file(self.name, self.component_id, 'pre_aggregated_gpkg', file_path)
            else:
                data_state.register_output_file(self.name, self.component_id, 'gpkg', file_path)

        data_state.update_infer_gdf(results_gdf)
        data_state.infer_gdf_columns_to_pass = columns_to_pass
        data_state.side_processes.append(future_coco)

        return data_state
